{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 5. Face Detection and Emotion Recognition (Курсовая работа)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно написать приложение, которое будет считывать и выводить кадры с веб-камеры. В процессе считывания определять что перед камерой находится человек, задетектировав его лицо на кадре. После этого, человек показывает жесты руками, а алгоритм должен считать их и определенным образом реагировать на эти жесты.\n",
    "На то, как система будет реагировать на определенные жесты - выбор за вами. Например, на определенный жест (жест пис), система будет здороваться с человеком. На другой, будет делать скриншот экрана. И т.д.\n",
    "Для распознавания жестов, вам надо будет скачать датасет https://www.kaggle.com/gti-upm/leapgestrecog, разработать модель для обучения и обучить эту модель.\n",
    "\n",
    "*(Усложненное задание) Все тоже самое, но воспользоваться этим датасетом:\n",
    "https://fitnessallyapp.com/datasets/jester/v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Использование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # Для обхода бага библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = self.conv_block(in_channels, 64)\n",
    "        self.conv2 = self.conv_block(64, 64, pool=True)\n",
    "        self.res1 = nn.Sequential(self.conv_block(64, 64), self.conv_block(64, 64))\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv3 = self.conv_block(64, 128)\n",
    "        self.conv4 = self.conv_block(128, 128, pool=True)\n",
    "        self.res2 = nn.Sequential(self.conv_block(128, 128), self.conv_block(128, 128))\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv5 = self.conv_block(128, 256)\n",
    "        self.conv6 = self.conv_block(256, 256, pool=True)\n",
    "        self.res3 = nn.Sequential(self.conv_block(256, 256), self.conv_block(256, 256))\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(6), \n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(256, num_classes))\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_block(in_channels, out_channels, pool=False):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "                  nn.BatchNorm2d(out_channels), \n",
    "                  nn.ELU(inplace=True)]\n",
    "        if pool: layers.append(nn.MaxPool2d(2))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.drop1(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.drop2(out)\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.drop3(out)\n",
    "        \n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс детектирования и обработки жестов с веб-камеры \n",
    "class GestureDetector(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = ResNet(1, 10).to(self.device)\n",
    "        self.model.load_state_dict(torch.load('./models/model1.pth'))\n",
    "        self.model.eval()\n",
    "\n",
    "    # Функция рисования найденных параметров на кадре\n",
    "    def _draw(self, frame, text):\n",
    "        try:\n",
    "            # пишем на кадре какой жест распознан\n",
    "            cv2.putText(frame, text, (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "            print('Something wrong im draw function!')\n",
    "\n",
    "        return frame\n",
    "    \n",
    "    @staticmethod\n",
    "    def digit_to_classname(digit):\n",
    "        if digit == 0:\n",
    "            return 'palm'\n",
    "        elif digit == 1:\n",
    "            return 'I'\n",
    "        elif digit == 2:\n",
    "            return 'fist'\n",
    "        elif digit == 3:\n",
    "            return 'fist_moved'\n",
    "        elif digit == 4:\n",
    "            return 'thumb'\n",
    "        elif digit == 5:\n",
    "            return 'index'\n",
    "        elif digit == 6:\n",
    "            return 'ok'\n",
    "        elif digit == 7:\n",
    "            return 'palm_moved'\n",
    "        elif digit == 8:\n",
    "            return 'c'\n",
    "        elif digit == 9:\n",
    "            return 'down'\n",
    "\n",
    "    # Функция в которой будет происходить процесс считывания и обработки каждого кадра\n",
    "    def run(self):              \n",
    "        # Заходим в бесконечный цикл\n",
    "        while True:\n",
    "            # Считываем каждый новый кадр - frame\n",
    "            # ret - логическая переменая. Смысл - считали ли мы кадр с потока или нет\n",
    "            ret, frame = cap.read()\n",
    "            #try:\n",
    "            transforms = tt.Compose([# Настройки для расширения датасета\n",
    "                         tt.Grayscale(num_output_channels=1), # Картинки чернобелые\n",
    "                         tt.Resize((64,64), interpolation=Image.BILINEAR),\n",
    "                         tt.ToTensor(),\n",
    "                         tt.Normalize((0.1307,), (0.3081,)),\n",
    "            ])                      # Приведение к тензору\n",
    "            gesture = transforms(Image.fromarray(frame))\n",
    "            # Меняем размер изображения для входа в нейронную сеть\n",
    "            #gesture = cv2.resize(frame,(64,64))\n",
    "            # Превращаем в 1-канальное серое изображение\n",
    "            #gesture = cv2.cvtColor(gesture, cv2.COLOR_BGR2GRAY)\n",
    "            # Превращаем numpy-картинку в pytorch-тензор\n",
    "            #torch_gesture = torch.from_numpy(gesture).unsqueeze(0).to(self.device).float()\n",
    "            torch_gesture = gesture.unsqueeze(0).to(self.device).float()\n",
    "            predict = self.model(torch_gesture.unsqueeze(0)[0])\n",
    "            # Интерпретируем предсказание как строку нашей эмоции\n",
    "            predict_text = self.digit_to_classname(predict.argmax())\n",
    "            # Рисуем на кадре\n",
    "            self._draw(frame, predict_text)\n",
    "            #self._draw(gesture, predict_text)\n",
    "            #plt.imshow(Image.fromarray(gesture))\n",
    "            #plt.imshow(gesture[0])\n",
    "\n",
    "            #except:\n",
    "            #    print('Something wrong im main cycle!')\n",
    "\n",
    "            # Показываем кадр в окне, и называем его(окно) - 'Gesture Detection'\n",
    "            cv2.imshow('Gesture Detection', frame)\n",
    "            \n",
    "            # Функция, которая проверяет нажатие на клавишу 'q'\n",
    "            # Если нажатие произошло - выход из цикла. Конец работы приложения\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        # Очищаем все объекты opencv, что мы создали\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "# Создаем объект для считывания потока с веб-камеры(обычно вебкамера идет под номером 0. иногда 1)\n",
    "cap = cv2.VideoCapture(0)  \n",
    "# Создаем объект нашего класса приложения\n",
    "fcd = GestureDetector()\n",
    "# Запускаем\n",
    "fcd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
