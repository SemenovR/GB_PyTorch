{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 5. Face Detection and Emotion Recognition (Курсовая работа)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно написать приложение, которое будет считывать и выводить кадры с веб-камеры. В процессе считывания определять что перед камерой находится человек, задетектировав его лицо на кадре. После этого, человек показывает жесты руками, а алгоритм должен считать их и определенным образом реагировать на эти жесты.\n",
    "На то, как система будет реагировать на определенные жесты - выбор за вами. Например, на определенный жест (жест пис), система будет здороваться с человеком. На другой, будет делать скриншот экрана. И т.д.\n",
    "Для распознавания жестов, вам надо будет скачать датасет https://www.kaggle.com/gti-upm/leapgestrecog, разработать модель для обучения и обучить эту модель.\n",
    "\n",
    "*(Усложненное задание) Все тоже самое, но воспользоваться этим датасетом:\n",
    "https://fitnessallyapp.com/datasets/jester/v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Обучение и использование в онлайн-режиме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает следующим образом. После запуска алгоритма откроется cv2 окно. В этом окне нужно показать некий жест и затем нажать на клавиатуре цифру 0. Тем самым модель будет запоминать этот жест под классом 0. Затем показать второй жест и нажать на клавиатуре цифру 1. Тем самым модель будет запоминать второй жест под классом 1. И так нужно повторять в течение нескольких минут (примерно 2-3 минуты). Т.е. показать первый жест - нажать на 0, показать второй жест - нажать на 1. Эти операции можно чередовать по разному. Сначала можно запоминать жесты в центре кадра, а затем пробовать смещать влево-вправо.\n",
    "Сверху экрана будет отображаться в первой строке предсказанный моделью класс (0 или 1). Во второй строке тензор с предсказаниями. В третьей строке значение ошибки. Нажатие на кнопку q - закрывает окно.\n",
    "\n",
    "Пример работы с обученной моделью: https://youtu.be/jN3DwbXl8U8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # Для обхода бага библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, size_n, size_p, debug):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.debug = debug\n",
    "        \n",
    "        size_pre = in_channels\n",
    "        size_cur = size_n\n",
    "        size_c = size_p / 2\n",
    "        self.conv1 = self.conv_block(size_pre, size_cur)\n",
    "        self.conv2 = self.conv_block(size_cur, size_cur, pool=True)\n",
    "        self.res1 = nn.Sequential(self.conv_block(size_cur, size_cur), self.conv_block(size_cur, size_cur))\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        \n",
    "        size_pre = size_cur\n",
    "        size_cur = size_cur * 2\n",
    "        size_c = size_c / 2\n",
    "        self.conv3 = self.conv_block(size_pre, size_cur)\n",
    "        self.conv4 = self.conv_block(size_cur, size_cur, pool=True)\n",
    "        self.res2 = nn.Sequential(self.conv_block(size_cur, size_cur), self.conv_block(size_cur, size_cur))\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        \n",
    "        size_pre = size_cur\n",
    "        size_cur = size_cur * 2\n",
    "        size_c = size_c / 2\n",
    "        self.conv5 = self.conv_block(size_pre, size_cur)\n",
    "        self.conv6 = self.conv_block(size_cur, size_cur, pool=True)\n",
    "        self.res3 = nn.Sequential(self.conv_block(size_cur, size_cur), self.conv_block(size_cur, size_cur))\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        size_k = 6\n",
    "        size_f = int((math.floor((size_c - size_k) / size_k) + 1)**2 * size_cur)\n",
    "        self.maxp = nn.MaxPool2d(size_k)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.line = nn.Linear(size_f, num_classes)\n",
    "        \n",
    "    @staticmethod\n",
    "    def conv_block(in_channels, out_channels, pool=False):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "                  nn.BatchNorm2d(out_channels), \n",
    "                  nn.ELU(inplace=True)]\n",
    "        if pool: layers.append(nn.MaxPool2d(2))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "    def call_layer(self, data, layer):\n",
    "        if self.debug == True:\n",
    "            print(self.counter, data.shape)\n",
    "            self.counter += 1\n",
    "        return layer(data)\n",
    "            \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        self.counter = 0\n",
    "        \n",
    "        out = self.call_layer(xb, self.conv1)\n",
    "        out = self.call_layer(out, self.conv2)\n",
    "        #out = self.call_layer(out, self.res1) + out\n",
    "        out = self.call_layer(out, self.drop1)\n",
    "        \n",
    "        out = self.call_layer(out, self.conv3)\n",
    "        out = self.call_layer(out, self.conv4)\n",
    "        #out = self.call_layer(out, self.res2) + out\n",
    "        out = self.call_layer(out, self.drop2)\n",
    "        \n",
    "        out = self.call_layer(out, self.conv5)\n",
    "        out = self.call_layer(out, self.conv6)\n",
    "        #out = self.call_layer(out, self.res3) + out\n",
    "        out = self.call_layer(out, self.drop3)\n",
    "\n",
    "        out = self.call_layer(out, self.maxp)\n",
    "        out = self.call_layer(out, self.flat)\n",
    "        out = self.call_layer(out, self.line)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Класс детектирования и обработки жестов с веб-камеры \n",
    "class GestureDetector(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 1     \n",
    "        self.channels = 1\n",
    "        self.classes = 2 #10\n",
    "        self.size_n = 512\n",
    "        self.size_p = 128\n",
    "\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = ResNet(self.channels, self.classes, self.size_n, self.size_p, False).to(self.device)\n",
    "\n",
    "        max_lr = 0.001\n",
    "        weight_decay = 1e-4\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    # Функция рисования найденных параметров на кадре\n",
    "    def _draw(self, frame, text0, text1, text2):\n",
    "        try:\n",
    "            # пишем на кадре какой жест распознан\n",
    "            cv2.putText(frame, text0, (30, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, text1, (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, text2, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        except:\n",
    "            print('Something wrong im draw function!')\n",
    "\n",
    "        return frame\n",
    "    \n",
    "    # Функция в которой будет происходить процесс считывания и обработки каждого кадра\n",
    "    def run(self):    \n",
    "\n",
    "        # Трансформации\n",
    "        transforms = tt.Compose([# Настройки для расширения датасета\n",
    "                                 tt.Grayscale(num_output_channels=1), # Картинки чернобелые\n",
    "                                 tt.Resize((self.size_p,self.size_p), interpolation=Image.NEAREST),\n",
    "                                 tt.ToTensor(),\n",
    "                                 tt.Normalize((0.1307,), (0.3081,)),\n",
    "        ])                      # Приведение к тензору\n",
    "        \n",
    "        train_on = False\n",
    "        label = 0\n",
    "        last_loss = ''\n",
    "        \n",
    "        # Заходим в бесконечный цикл\n",
    "        while True:\n",
    "            # Считываем каждый новый кадр - frame\n",
    "            # ret - логическая переменая. Смысл - считали ли мы кадр с потока или нет\n",
    "            ret, frame = cap.read()\n",
    "            #try:\n",
    "            \n",
    "            if train_on == True:\n",
    "                train_on = False\n",
    "                running_loss = 0.0\n",
    "\n",
    "                for i in range(self.epoch):\n",
    "                    data = Variable(transforms(Image.fromarray(frame))).unsqueeze(0)\n",
    "                    labels = Variable(torch.tensor([label]))\n",
    "                    data = data.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    outputs = self.model(data)\n",
    "                    #print(outputs, labels)\n",
    "                    \n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    data.detach().cpu()\n",
    "                    labels.detach().cpu()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    \n",
    "                last_loss = f'{running_loss/self.epoch}'\n",
    "                \n",
    "\n",
    "            with torch.no_grad():\n",
    "                data = Variable(transforms(Image.fromarray(frame))).unsqueeze(0).to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                last_test = f'{outputs[0]}'\n",
    "                predict_text = f'predict: {outputs[0].argmax()}'\n",
    "                data.detach().cpu()\n",
    "\n",
    "\n",
    "            # Рисуем на кадре\n",
    "            self._draw(frame, predict_text, last_test, last_loss)\n",
    "\n",
    "            #except:\n",
    "                #print('Something wrong im main cycle!')\n",
    "\n",
    "            # Показываем кадр в окне, и называем его(окно) - 'Gesture Detection'\n",
    "            cv2.imshow('Gesture Detection', frame)\n",
    "            \n",
    "            # Функция, которая проверяет нажатие на клавишу 'q'\n",
    "            # Если нажатие произошло - выход из цикла. Конец работы приложения\n",
    "            key = chr(cv2.waitKey(1) & 0xFF)\n",
    "            if key == 'q':\n",
    "                break\n",
    "            elif key >= '0' and key <= '9': # Для выбора номера класса\n",
    "                label = int(key)\n",
    "                train_on = True\n",
    "                \n",
    "        # Очищаем все объекты opencv, что мы создали\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "# Создаем объект для считывания потока с веб-камеры(обычно вебкамера идет под номером 0. иногда 1)\n",
    "cap = cv2.VideoCapture(0)  \n",
    "# Создаем объект нашего класса приложения\n",
    "fcd = GestureDetector()\n",
    "# Запускаем\n",
    "fcd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
